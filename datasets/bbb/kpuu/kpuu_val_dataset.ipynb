{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import inchi\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from chembl_structure_pipeline import standardizer as ChEMBL_standardizer\n",
    "from papyrus_structure_pipeline import standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_raw =  pd.read_excel('Kpuu_raw.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(row):\n",
    "    if row['Kp,uu,brain'] > 0.33:\n",
    "        return 'active'\n",
    "    elif row['Kp,uu,brain'] <= 0.1:\n",
    "        return 'inactive'\n",
    "    else:\n",
    "        return '?'\n",
    "\n",
    "kpuu_raw['status_activity'] = kpuu_raw.apply(compare_values, axis=1)\n",
    "\n",
    "kpuu_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_raw = kpuu_raw.rename(columns={'SMILES': 'SMILES_raw'})\n",
    "\n",
    "columns_to_keep = ['SMILES_raw', 'status_activity', 'species']\n",
    "kpuu = kpuu_raw[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows without SMILES\n",
    "\n",
    "def remove_nan_smiles(df):\n",
    "\n",
    "    df = df[~(df['SMILES_raw'].isna())]\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Papyrus Standardization\n",
    "\n",
    "def create_sd_smiles(sd_mol):\n",
    "    try:\n",
    "        standardized_smiles =  Chem.MolToSmiles(sd_mol)\n",
    "        return standardized_smiles\n",
    "    except Exception as e:\n",
    "        print(f\"An sd_smiles error occurred: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "#Create InChI keys from standardized molecules\n",
    "def mol_to_inchi_key(sd_mol):\n",
    "    if sd_mol is not None:\n",
    "\n",
    "        inchi_str = inchi.MolToInchi(sd_mol)\n",
    "        inchi_key = inchi.InchiToInchiKey(inchi_str)\n",
    "    else:\n",
    "        inchi_key = None   \n",
    "    return inchi_key\n",
    "\n",
    "def standardize_molecule(mol):\n",
    "    standardized_mol =  standardize(mol,raise_error=False )\n",
    "    return standardized_mol\n",
    "\n",
    "#Standardize \n",
    "\n",
    "def standardize_workflow(df_raw):\n",
    "    for i in range(0,len(df_raw)):\n",
    "        smiles =df_raw.at[i,'SMILES_raw']\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        sd_mol =  standardize_molecule(mol)\n",
    "        sd_smiles = create_sd_smiles(sd_mol)\n",
    "        sd_inchi_key = mol_to_inchi_key(sd_mol)\n",
    "        df_raw.at[i,'papyrus_SMILES'] = sd_smiles\n",
    "        df_raw.at[i,'papyrus_inchi_key'] = sd_inchi_key\n",
    "\n",
    "    print(f'df length after standardization: {len(df_raw)}')\n",
    "\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing inchi key\n",
    "\n",
    "def missing_inchi(df_raw):\n",
    "    smiles_nan = df_raw['papyrus_SMILES'].isna().sum()\n",
    "    inchikey_nan =df_raw['papyrus_inchi_key'].isna().sum()\n",
    "    print(f'DB length: {len(df_raw)},        SMILES nan: {smiles_nan},        inchi key nan: {inchikey_nan}')\n",
    "\n",
    "    #Remove rows with missing inchikey\n",
    "    df_valid_inchi= df_raw[((df_raw['papyrus_inchi_key'].notna()))]\n",
    "    print('-----remove missing inchikey----')\n",
    "    print(f'updated length: {len(df_valid_inchi)}')\n",
    "\n",
    "    return df_valid_inchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inchi_first_part(inchi):\n",
    "    return inchi.split('-')[0]\n",
    "\n",
    "def create_connectivity_inchi(df):\n",
    "    df['inchi_connectivity'] = df['papyrus_inchi_key'].apply(inchi_first_part)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for duplicates\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    print(f'length: {len(df)}')\n",
    "    inchi_un = df['inchi_connectivity'].nunique()\n",
    "    print(f'unique_inchi: {inchi_un}')\n",
    "\n",
    "\n",
    "    unique_counts = df.groupby('inchi_connectivity')['status_activity'].nunique()\n",
    "    contradicting_duplicates = unique_counts[unique_counts > 1].index\n",
    "\n",
    "    print(f'Contradicting duplicates: {len(contradicting_duplicates)}')\n",
    "\n",
    "    # Separate contradicting duplicates into a new dataframe\n",
    "    duplicates_df = df[df['inchi_connectivity'].isin(contradicting_duplicates)].copy()\n",
    "\n",
    "    # Remove contradicting duplicates from the original dataframe\n",
    "    df = df[~df['inchi_connectivity'].isin(contradicting_duplicates)].copy()\n",
    "\n",
    "    print(f'Original dataframe after contradicting duplicates removed: {len(df)}')\n",
    "    print(f'Original dataframe unique_inchi after removal: {df[\"inchi_connectivity\"].nunique()}')\n",
    "\n",
    "    df=df.drop_duplicates(subset=['inchi_connectivity'], keep=\"first\").reset_index(drop=True)\n",
    "    \n",
    "    print(f'Original dataframe after non-contradicting duplicates removed: {len(df)}')\n",
    "\n",
    "    return df, duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kpuu\n",
    "\n",
    "df = remove_nan_smiles(df)\n",
    "\n",
    "df_sd = standardize_workflow(df)\n",
    "df_sd.to_csv('kpuu_standardized_val.csv')\n",
    "\n",
    "df_valid = missing_inchi(df_sd)\n",
    "df_valid.to_csv('kpuu_have_inchi_key_val.csv')\n",
    "\n",
    "df_connectivity_inchi = create_connectivity_inchi(df_valid)\n",
    "df_connectivity_inchi.to_csv('kpuu_connectivity_inchi_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_duplicates, df_contra_duplicates = remove_duplicates(df_connectivity_inchi)\n",
    "df_no_duplicates.to_csv('kpuu_no_duplicates_val.csv')\n",
    "df_contra_duplicates.to_csv('kpuu_contradicting_duplicates.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further curate contradicting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further curate contradicting\n",
    "\n",
    "\n",
    "print(f'length: {len(df)}')\n",
    "\n",
    "unique_counts = df_contra_duplicates.groupby('inchi_connectivity')['species'].nunique()\n",
    "same_species = unique_counts[unique_counts >  1].index\n",
    "\n",
    "print(f'Dupicates with same species: {len(same_species)}')\n",
    "\n",
    "\n",
    "# Create a mask to identify the first entries of duplicates with the same species\n",
    "df_unique = df_contra_duplicates.drop_duplicates(subset=['inchi_connectivity', 'species'], keep='first').reset_index(drop=True)\n",
    "\n",
    "print(f'Length after inchi-key AND species duplicates are removed: {len(df_unique)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique.to_csv('kpuu_contradicting_duplicates_once.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove training molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influx = pd.read_csv('../../../3_Combined/31_Combined_datasets/1_data_curation/influx/combined_influx_train_raw.csv')\n",
    "efflux = pd.read_csv('../../../3_Combined/31_Combined_datasets/1_data_curation/efflux/combined_efflux_train_raw.csv')\n",
    "pampa = pd.read_csv('../../../3_Combined/31_Combined_datasets/1_data_curation/pampa/combined_pampa_train_raw.csv')\n",
    "bbb = pd.read_csv('../../../3_Combined/31_Combined_datasets/1_data_curation/bbb/combined_bbb_train_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_no_duplicates['inchi_connectivity'].isin(influx['inchi_connectivity'])\n",
    "common_values_list = df_no_duplicates[mask]['inchi_connectivity'].tolist()\n",
    "print(f'Common molecules {len(common_values_list)}')\n",
    "kpuu_val = df_no_duplicates[~mask]\n",
    "kpuu_val = kpuu_val.reset_index(drop=True)\n",
    "print(f'After removed: {len(kpuu_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kpuu_val['inchi_connectivity'].isin(efflux['inchi_connectivity'])\n",
    "common_values_list = kpuu_val[mask]['inchi_connectivity'].tolist()\n",
    "print(f'Common molecules {len(common_values_list)}')\n",
    "kpuu_val = kpuu_val[~mask]\n",
    "kpuu_val = kpuu_val.reset_index(drop=True)\n",
    "print(f'After removed: {len(kpuu_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kpuu_val['inchi_connectivity'].isin(pampa['inchi_connectivity'])\n",
    "common_values_list = kpuu_val[mask]['inchi_connectivity'].tolist()\n",
    "print(f'Common molecules {len(common_values_list)}')\n",
    "kpuu_val = kpuu_val[~mask]\n",
    "kpuu_val = kpuu_val.reset_index(drop=True)\n",
    "print(f'After removed: {len(kpuu_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = kpuu_val['inchi_connectivity'].isin(bbb['inchi_connectivity'])\n",
    "common_values_list = kpuu_val[mask]['inchi_connectivity'].tolist()\n",
    "print(f'Common molecules {len(common_values_list)}')\n",
    "kpuu_val = kpuu_val[~mask]\n",
    "kpuuval = kpuu_val.reset_index(drop=True)\n",
    "print(f'After removed: {len(kpuu_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_val.to_csv('kpuu_validation_not_everything_classified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_val_classified = kpuu_val[kpuu_val['status_activity'].isin(['active', 'inactive'])]\n",
    "len(kpuu_val_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpuu_val_classified.to_csv('kpuu_validation.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
