{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from pycaret.classification import setup, compare_models\n",
    "from pycaret.classification import tune_model\n",
    "from pycaret.classification import *\n",
    "from sklearn.metrics import balanced_accuracy_score, matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pycaret.classification import load_model\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the top3 classifier that has prediction score - for all transport and feature combination\n",
    "\n",
    "def define_models(t,feature):\n",
    "\n",
    "    if feature == \"submd\":\n",
    "        if t ==\"influx\":\n",
    "            models =  ['XGBClassifier','RandomForestClassifier','GradientBoostingClassifier']\n",
    "\n",
    "        elif t ==\"efflux\":\n",
    "            models = ['LGBMClassifier','ExtraTreesClassifier','RandomForestClassifier']\n",
    "\n",
    "        elif t ==\"pampa\":\n",
    "            models = ['RandomForestClassifier','ExtraTreesClassifier','GradientBoostingClassifier']\n",
    "\n",
    "        elif t ==\"bbb\":\n",
    "            models = [\"LGBMClassifier\",\"XGBClassifier\",\"ExtraTreesClassifier\"]\n",
    "\n",
    "    elif feature == \"subfp\":\n",
    "        if t ==\"influx\":\n",
    "            models =  ['AdaBoostClassifier','LinearDiscriminantAnalysis','LGBMClassifier']\n",
    "\n",
    "        elif t ==\"efflux\":\n",
    "            models = ['LGBMClassifier','XGBClassifier','ExtraTreesClassifier']\n",
    "\n",
    "        elif t ==\"pampa\":\n",
    "            models = ['XGBClassifier','GradientBoostingClassifier','LogisticRegression']\n",
    "\n",
    "        elif t ==\"bbb\":\n",
    "            models = [\"LogisticRegression\",\"ExtraTreesClassifier\",\"KNeighborsClassifier\"]\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the DrugBank and Kpuu dataset\n",
    "\n",
    "def load_df(valset,feature):\n",
    "\n",
    "    if valset == \"cns\":\n",
    "            file_name = f'../CNS/2_feature_creation/cns_validation_{feature}.csv'\n",
    "\n",
    "    elif valset == \"kpuu\":\n",
    "          file_name = f'../Kpuu/2_feature_creation/kpuu_validation_{feature}.csv'\n",
    "\n",
    "    df = pd.read_csv(file_name, index_col=0)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the trained model\n",
    "\n",
    "def load_the_model(t,f,model_name):\n",
    "    model_file = f'../models/{f}/combined_{f}_{t}_{model_name}_session_16_{f}'\n",
    "    model = load_model(model_file)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make prediction\n",
    "\n",
    "def make_prediction(model,df):\n",
    "    predictions = predict_model(model, data=df, raw_score=True)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataset to keep only the prediction relevant information\n",
    "\n",
    "def clean_df_for_info(df,valset):\n",
    "\n",
    "    if valset ==\"kpuu\":\n",
    "        columns_to_keep = ['status_activity','species','papyrus_SMILES','inchi_connectivity']\n",
    "    elif valset ==\"cns\":\n",
    "        columns_to_keep = ['status_cns','papyrus_SMILES','papyrus_inchi_key','inchi_connectivity']\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the average prediction score\n",
    "\n",
    "def calculate_average(df):\n",
    "\n",
    "    avg = df.iloc[:, [-6, -4, -2]].mean(axis=1)\n",
    "    avg_values_list = avg.tolist()\n",
    "\n",
    "    return avg_values_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the variables to iterate through\n",
    "\n",
    "features = ['submd','subfp']\n",
    "transports = ['influx','efflux','pampa','bbb']\n",
    "valsets = [\"kpuu\",'cns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we perform prediction separately for each target label: influx, efflux, PAMPA, BBB\n",
    "#We collect prediction score, predicted class for each model and calculate average pred score and \n",
    "\n",
    "for valset in valsets:\n",
    "    for f in features:\n",
    "        df_raw = load_df(valset,f)\n",
    "        df_info = clean_df_for_info(df_raw,valset)\n",
    "\n",
    "        for t in transports: \n",
    "            models = define_models(t,f)\n",
    "            print(f'{f} - {t} -{valset}')\n",
    "\n",
    "            #Iterate through the models and make predictions\n",
    "            for m in models:\n",
    "                classifier = load_the_model(t,f,m)\n",
    "\n",
    "                predictions = make_prediction(classifier,df_raw)\n",
    "\n",
    "                pred_classes = predictions['prediction_label'].values\n",
    "                probability_score= predictions['prediction_score_1'].values\n",
    "\n",
    "                column_mod_score=f'{m}_pred_score_{t}'\n",
    "                df_info[column_mod_score] = probability_score\n",
    "\n",
    "                column_mod_class = f'{m}_pred_class_{t}'\n",
    "                df_info[column_mod_class] = pred_classes\n",
    "\n",
    "            #Calculate average prediction scre\n",
    "            pred_score_means = calculate_average(df_info)\n",
    "            column_score_mean = f'{t}_pred_score_mean'\n",
    "            df_info[column_score_mean] = pred_score_means\n",
    "\n",
    "            #Get the majority vote for final label\n",
    "            counts = df_info.iloc[:, [-6, -4, -2]].apply(lambda x: (x == 1).sum(), axis=1)\n",
    "            column_maj_class =f'{t}_majority_class'\n",
    "            df_info[column_maj_class] = counts.apply(lambda x: 1 if x > 1 else 0)\n",
    "\n",
    "        #Save the predictions\n",
    "        file_name = f'{valset}_{f}_pred_scores_class.csv'\n",
    "        df_info.to_csv(file_name, index=True)\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the file with majority vote information\n",
    "\n",
    "def load_maj_class_files(valset,feature):\n",
    "    file_name = f'{valset}_{feature}_pred_scores_class.csv'\n",
    "    df = pd.read_csv(file_name, index_col=0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valsets = ['cns']\n",
    "transports =['influx','efflux','pampa','bbb']\n",
    "features = ['submd', 'subfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create swarm plot to investigate pred.score\n",
    "def make_plot(df, valset,t,f):\n",
    "\n",
    "    plt.figure(figsize=(3, 3))  # Adjust figure size if needed\n",
    "\n",
    "\n",
    "    if valset == \"cns\":\n",
    "\n",
    "        y_name = f'{t}_score'\n",
    "        \n",
    "        sns.swarmplot(data=df, x=\"status_cns\", y=y_name, color='blue', alpha=0.5)  # Swarm plot\n",
    "        #sns.boxplot(data=df, x=\"status_cns\", y=\"comp_score_1\", color='red', width=0.3)\n",
    "        plt.xlabel(\"Targeting\")\n",
    "        plt.ylabel(\"Prediction Score\")\n",
    "        valset_title = 'DrugBank'\n",
    "\n",
    "    elif valset == \"kpuu\":\n",
    "        \n",
    "        y_name = f'{t}_score'\n",
    "        sns.swarmplot(data=df, x=\"status_activity\", y=y_name , color='blue', alpha=0.5)  # Swarm plot\n",
    "        #sns.boxplot(data=df, x=\"status_activity\", y=\"comp_score_1\", color='red', width=0.3)\n",
    "        plt.xlabel(\"Activity\")\n",
    "        plt.ylabel(\"Prediction Score\")\n",
    "        valset_title = \"Kp,uu\"\n",
    "\n",
    "    if t == \"influx\":\n",
    "        t_title =\"Influx\"\n",
    "    elif t ==\"efflux\":\n",
    "        t_title =\"Efflux\"\n",
    "    elif t==\"pampa\":\n",
    "        t_title=\"PAMPA\"\n",
    "    elif t==\"bbb\":\n",
    "        t_title=\"BBB\"\n",
    "\n",
    "    if f ==\"submd\":\n",
    "        f_title =\"Molecular Descriptors\"\n",
    "    elif f ==\"subfp\":\n",
    "        f_title=\"Molecular Fingerprints\"\n",
    "\n",
    "    plt.title(f'{t_title} Prediction Score with \\n{f_title} on {valset_title}', fontsize=11)\n",
    "\n",
    "\n",
    "    plt.gcf().set_size_inches(3, 3)\n",
    "    file_name_svg = f'../plots_for_report/{valset}_{t}_{f}.svg'\n",
    "    plt.savefig(file_name_svg, bbox_inches='tight')\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the functions\n",
    "\n",
    "for valset in valsets:\n",
    "    for f in features:\n",
    "        df = load_maj_class_files(valset,f)\n",
    "        \n",
    "        df['influx_score'] = df['influx_majority_class'] * df['influx_pred_score_mean']\n",
    "        df['efflux_score'] = df['efflux_majority_class'] * df['efflux_pred_score_mean']\n",
    "        df['pampa_score'] = df['pampa_majority_class'] * df['pampa_pred_score_mean']\n",
    "        df['bbb_score'] = df['bbb_majority_class'] * df['bbb_pred_score_mean']\n",
    "    \n",
    "        for t in transports:\n",
    "            make_plot(df, valset,t,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
